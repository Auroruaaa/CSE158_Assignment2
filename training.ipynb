{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('./df_movies_final.csv')\n",
    "ratings_df = pd.read_csv('./ratings_without_timestamp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllRatings = ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733150</th>\n",
       "      <td>5000</td>\n",
       "      <td>1073</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733151</th>\n",
       "      <td>5000</td>\n",
       "      <td>1210</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733152</th>\n",
       "      <td>5000</td>\n",
       "      <td>1356</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733153</th>\n",
       "      <td>5000</td>\n",
       "      <td>1393</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733154</th>\n",
       "      <td>5000</td>\n",
       "      <td>1416</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "0            1      296     5.0\n",
       "1            1      306     3.5\n",
       "2            1      307     5.0\n",
       "3            1      665     5.0\n",
       "4            1      899     3.5\n",
       "...        ...      ...     ...\n",
       "733150    5000     1073     2.0\n",
       "733151    5000     1210     3.0\n",
       "733152    5000     1356     3.0\n",
       "733153    5000     1393     4.0\n",
       "733154    5000     1416     2.0\n",
       "\n",
       "[733155 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllRatings_sub = AllRatings[AllRatings['userId'] <= 5000]\n",
    "AllRatings_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_size = AllRatings\n",
    "AllRatings_sub = AllRatings_sub.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "AllRatings_sub = AllRatings_sub.to_numpy()\n",
    "ratingsTrain = AllRatings_sub[:int(len(AllRatings_sub)*0.6)]\n",
    "ratingsValid = AllRatings_sub[int(len(AllRatings_sub)*0.6):int(len(AllRatings_sub)*0.8)]\n",
    "ratingsTest = AllRatings_sub[int(len(AllRatings_sub)*0.8):]\n",
    "\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "ratingOnly = [] # to calculate global average\n",
    "ratingDict = {}\n",
    "userID, itemID = set(), set()\n",
    "\n",
    "for user, item, rating in ratingsTrain:\n",
    "    user, item, rating = str(int(user)), str(int(item)), rating\n",
    "    userID.add(user)\n",
    "    itemID.add(item)\n",
    "\n",
    "    ratingsPerUser[user].append((item,rating))\n",
    "    ratingsPerItem[item].append((user,rating))\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    ratingDict[(user,item)] = rating\n",
    "    ratingOnly.append(rating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7738235360013701\n"
     ]
    }
   ],
   "source": [
    "# Grace version\n",
    "\n",
    "def preprocess_data(ratingsTrain):\n",
    "    user_ratings = defaultdict(list)\n",
    "    item_ratings = defaultdict(list)\n",
    "    all_ratings = []\n",
    "    for u, i, r in ratingsTrain:\n",
    "        rating = int(r)\n",
    "        user_ratings[u].append((i, rating))\n",
    "        item_ratings[i].append((u, rating))\n",
    "        all_ratings.append(rating)\n",
    "    return user_ratings, item_ratings, all_ratings\n",
    "\n",
    "def compute_biases(user_ratings, item_ratings, global_average, lamb):\n",
    "    \"\"\"Compute user and item biases using gradient descent.\"\"\"\n",
    "    user_bias = {u: 0 for u in user_ratings}\n",
    "    item_bias = {i: 0 for i in item_ratings}\n",
    "    \n",
    "    # Gradient descent for biases\n",
    "    for iteration in range(50):  # Fixed number of iterations\n",
    "        # Update user biases\n",
    "        for u in user_ratings:\n",
    "            user_bias[u] = sum(r - (global_average + item_bias[i]) for i, r in user_ratings[u]) / (\n",
    "                lamb + len(user_ratings[u])\n",
    "            )\n",
    "        # Update item biases\n",
    "        for i in item_ratings:\n",
    "            item_bias[i] = sum(r - (global_average + user_bias[u]) for u, r in item_ratings[i]) / (\n",
    "                lamb + len(item_ratings[i])\n",
    "            )\n",
    "    return user_bias, item_bias\n",
    "\n",
    "def rating_prediction(ratingsValid, lamb=5.0):\n",
    "    \"\"\"Predict ratings using user and item biases.\"\"\"\n",
    "    user_ratings, item_ratings, all_ratings = preprocess_data(ratingsTrain)\n",
    "    global_average = np.mean(all_ratings)\n",
    "    user_bias, item_bias = compute_biases(user_ratings, item_ratings, global_average, lamb)\n",
    "\n",
    "    pred_rating = []\n",
    "    true_rating = []\n",
    "    for u, i, r in ratingsValid:\n",
    "        p = global_average + user_bias.get(u, 0) + item_bias.get(i, 0)\n",
    "        true_rating.append(r)\n",
    "        pred_rating.append(p)\n",
    "    mse = MSE(pred_rating, true_rating)\n",
    "    print(mse)\n",
    "\n",
    "rating_prediction(ratingsValid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_data(train_path):\n",
    "#     \"\"\"Preprocess data to extract user and item biases.\"\"\"\n",
    "#     user_ratings = defaultdict(list)\n",
    "#     item_ratings = defaultdict(list)\n",
    "#     all_ratings = []\n",
    "    \n",
    "#     # Collect user-item pairs with ratings\n",
    "#     for user, book, rating in readCSV(train_path):\n",
    "#         rating = int(rating)\n",
    "#         user_ratings[user].append((book, rating))\n",
    "#         item_ratings[book].append((user, rating))\n",
    "#         all_ratings.append(rating)\n",
    "    \n",
    "#     return user_ratings, item_ratings, all_ratings\n",
    "\n",
    "# user_ratings = ratingsPerUser\n",
    "# item_ratings = ratingsPerItem\n",
    "# all_ratings = ratingOnly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_biases(user_ratings, item_ratings, global_average, lamb):\n",
    "    \"\"\"Compute user and item biases using gradient descent.\"\"\"\n",
    "    user_bias = {u: 0 for u in user_ratings}\n",
    "    item_bias = {i: 0 for i in item_ratings}\n",
    "    \n",
    "    # Gradient descent for biases\n",
    "    for iteration in range(50):  # Fixed number of iterations\n",
    "        # Update user biases\n",
    "        for u in user_ratings:\n",
    "            user_bias[u] = sum(r - (global_average + item_bias[i]) for i, r in user_ratings[u]) / (\n",
    "                lamb + len(user_ratings[u])\n",
    "            )\n",
    "        # Update item biases\n",
    "        for i in item_ratings:\n",
    "            item_bias[i] = sum(r - (global_average + user_bias[u]) for u, r in item_ratings[i]) / (\n",
    "                lamb + len(item_ratings[i])\n",
    "            )\n",
    "         \n",
    "    return user_bias, item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rating_prediction(train_path, test_path, output_path, lamb=5.0):\n",
    "def rating_prediction(ratingsValid, lamb=5.0):\n",
    "\n",
    "    \"\"\"Predict ratings using user and item biases.\"\"\"\n",
    "    user_ratings, item_ratings, all_ratings = ratingsPerUser, ratingsPerItem, ratingOnly\n",
    "    global_average = np.mean(all_ratings)\n",
    "    user_bias, item_bias = compute_biases(user_ratings, item_ratings, global_average, lamb)\n",
    "\n",
    "    # # Predict on the test set\n",
    "    # with open(output_path, 'w') as predictions:\n",
    "    #     predictions.write(\"userID,bookID,prediction\\n\")\n",
    "    #     for line in open(test_path):\n",
    "    #         if line.startswith(\"userID\"):\n",
    "    #             continue\n",
    "    #         user, book = line.strip().split(',')\n",
    "    #         pred = global_average + user_bias.get(user, 0) + item_bias.get(book, 0)\n",
    "    #         predictions.write(f\"{user},{book},{pred:.2f}\\n\")\n",
    "    pred_rating = []\n",
    "    true_rating = []\n",
    "    for u, i, r in ratingsValid:\n",
    "        p = global_average + user_bias.get(u, 0) + item_bias.get(i, 0)\n",
    "        true_rating.append(r)\n",
    "        pred_rating.append(p)\n",
    "    mse = MSE(pred_rating, true_rating)\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lambda(train_path, test_path, validation_path):\n",
    "    \"\"\"Find the optimal lambda value for rating prediction.\"\"\"\n",
    "    best_lambda = None\n",
    "    best_mse = float('inf')\n",
    "    for lamb in np.arange(1.0, 10.1, 0.5):\n",
    "        output_path = \"predictions_Validation.csv\"\n",
    "        rating_prediction(train_path, validation_path, output_path, lamb=lamb)\n",
    "        true_ratings = [int(line.strip().split(',')[2]) for line in open(validation_path) if not line.startswith(\"userID\")]\n",
    "        pred_ratings = [float(line.strip().split(',')[2]) for line in open(output_path) if not line.startswith(\"userID\")]\n",
    "        mse = MSE(true_ratings, pred_ratings)\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_lambda = lamb\n",
    "    print(f\"Best Lambda: {best_lambda}, Best MSE: {best_mse}\")\n",
    "    return best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_rating_predictions():\n",
    "    train_path = \"train_Interactions.csv.gz\"\n",
    "    test_path = \"pairs_Rating.csv\"\n",
    "    predictions_path = \"predictions_Rating.csv\"\n",
    "    rating_prediction(ratingsValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1000496208108885\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    output_rating_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Validation MSE: 0.8095351285851702\n",
      "Epoch 2/40, Validation MSE: 0.7833409579031452\n",
      "Epoch 3/40, Validation MSE: 0.7724539950360055\n",
      "Epoch 4/40, Validation MSE: 0.7665107008245938\n",
      "Epoch 5/40, Validation MSE: 0.7628291333981808\n",
      "Epoch 6/40, Validation MSE: 0.7603709818138574\n",
      "Epoch 7/40, Validation MSE: 0.7586445599239138\n",
      "Epoch 8/40, Validation MSE: 0.7573868074140805\n",
      "Epoch 9/40, Validation MSE: 0.7564447957696249\n",
      "Epoch 10/40, Validation MSE: 0.7557240183371043\n",
      "Epoch 11/40, Validation MSE: 0.7551632406432471\n",
      "Epoch 12/40, Validation MSE: 0.754721250169726\n",
      "Epoch 13/40, Validation MSE: 0.7543694269527974\n",
      "Epoch 14/40, Validation MSE: 0.754087363452561\n",
      "Epoch 15/40, Validation MSE: 0.7538601730522678\n",
      "Epoch 16/40, Validation MSE: 0.7536767778727188\n",
      "Epoch 17/40, Validation MSE: 0.7535287870842289\n",
      "Epoch 18/40, Validation MSE: 0.7534097432748597\n",
      "Epoch 19/40, Validation MSE: 0.7533146048545979\n",
      "Epoch 20/40, Validation MSE: 0.7532393836107224\n",
      "Epoch 21/40, Validation MSE: 0.7531808864705776\n",
      "Epoch 22/40, Validation MSE: 0.7531365286013166\n",
      "Epoch 23/40, Validation MSE: 0.7531041961819716\n",
      "Epoch 24/40, Validation MSE: 0.7530821442970994\n",
      "Epoch 25/40, Validation MSE: 0.753068920012967\n",
      "Epoch 26/40, Validation MSE: 0.7530633037430959\n",
      "Epoch 27/40, Validation MSE: 0.753064264055539\n",
      "Epoch 28/40, Validation MSE: 0.7530709224688804\n",
      "Epoch 29/40, Validation MSE: 0.753082525747888\n",
      "Epoch 30/40, Validation MSE: 0.7530984238843814\n",
      "Epoch 31/40, Validation MSE: 0.752262988085027\n",
      "Epoch 32/40, Validation MSE: 0.7520535071100112\n",
      "Epoch 33/40, Validation MSE: 0.7519757191449385\n",
      "Epoch 34/40, Validation MSE: 0.7519406090109954\n",
      "Epoch 35/40, Validation MSE: 0.7519226696147446\n",
      "Epoch 36/40, Validation MSE: 0.7519126359311578\n",
      "Epoch 37/40, Validation MSE: 0.7519066125762819\n",
      "Epoch 38/40, Validation MSE: 0.7519027916286873\n",
      "Epoch 39/40, Validation MSE: 0.751900271231956\n",
      "Epoch 40/40, Validation MSE: 0.7518985748542175\n"
     ]
    }
   ],
   "source": [
    "lambda_reg = 0.2\n",
    "learning_rate = 0.01\n",
    "n_epochs = 40\n",
    "K = 5\n",
    "\n",
    "best_mse = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "# \n",
    "ratings_train = [rating for _, _, rating in ratingsTrain]\n",
    "alpha = np.mean(ratings_train)\n",
    "\n",
    "user_biases = defaultdict(float)\n",
    "item_biases = defaultdict(float)\n",
    "\n",
    "userGamma = defaultdict(lambda: [0.0] * K, {user: [random.random() * 0.1 - 0.05 for _ in range(K)] for user in ratingsPerUser})\n",
    "itemGamma = defaultdict(lambda: [0.0] * K, {item: [random.random() * 0.1 - 0.05 for _ in range(K)] for item in ratingsPerItem})\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    if epoch < 30:\n",
    "        learning_rate = 0.01\n",
    "    else:\n",
    "        learning_rate = 0.001\n",
    "\n",
    "    for user, item, rating in ratingsTrain:\n",
    "        if user not in userGamma:\n",
    "            userGamma[user] = [random.random() * 0.1 - 0.05 for _ in range(K)]\n",
    "        if item not in itemGamma:\n",
    "            itemGamma[item] = [random.random() * 0.1 - 0.05 for _ in range(K)]\n",
    "        \n",
    "        prediction = alpha + user_biases.get(user, 0) + item_biases.get(item, 0) + inner(userGamma[user], itemGamma[item])\n",
    "        error = rating - prediction\n",
    "\n",
    "        user_biases[user] += learning_rate * (error - lambda_reg * user_biases[user])\n",
    "        item_biases[item] += learning_rate * (error - lambda_reg * item_biases[item])\n",
    "        \n",
    "        for k in range(K):\n",
    "            userGamma[user][k] += learning_rate * (error * itemGamma[item][k] - lambda_reg * userGamma[user][k])\n",
    "            itemGamma[item][k] += learning_rate * (error * userGamma[user][k] - lambda_reg * itemGamma[item][k])\n",
    "\n",
    "    squared_errors = []\n",
    "    for user, item, rating in ratingsValid:\n",
    "        prediction = alpha + user_biases.get(user, 0) + item_biases.get(item, 0) + inner(userGamma.get(user, [0] * K), itemGamma.get(item, [0] * K))\n",
    "        squared_errors.append((rating - prediction) ** 2)\n",
    "    mse = np.mean(squared_errors)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Validation MSE: {mse}\")\n",
    "\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping...\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>653</td>\n",
       "      <td>139299</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3854</td>\n",
       "      <td>1466</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4554</td>\n",
       "      <td>8360</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>6711</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1866</td>\n",
       "      <td>90531</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439888</th>\n",
       "      <td>2096</td>\n",
       "      <td>4993</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439889</th>\n",
       "      <td>3554</td>\n",
       "      <td>5349</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439890</th>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439891</th>\n",
       "      <td>2379</td>\n",
       "      <td>4356</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439892</th>\n",
       "      <td>1336</td>\n",
       "      <td>3916</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439893 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "0          653   139299     2.5\n",
       "1         3854     1466     5.0\n",
       "2         4554     8360     3.5\n",
       "3           84     6711     4.0\n",
       "4         1866    90531     4.0\n",
       "...        ...      ...     ...\n",
       "439888    2096     4993     4.0\n",
       "439889    3554     5349     5.0\n",
       "439890      85       21     4.0\n",
       "439891    2379     4356     3.5\n",
       "439892    1336     3916     5.0\n",
       "\n",
       "[439893 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
